Indexing: To insert Data (Document)

Field: An attribute of the document (E.g Name, ID, Description, etc.)


Mappings:
- Define fields of a document (Data Types, Operations to execute when indexing, etc)
- String field can be indexed as a 'text' field for full-text search, and 'keyword' field for sorting/aggregations

Field Mapping parameters can be found here:
https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html

Data Types can be found here:
https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html

<Sample>

{
    "mappings": {
        "properties": {
            // DEFINE MAPPINGS FOR FIELDS HERE
        }
    }
}

E.g

{
    "mappings": {
        "properties": {
            // The field you are mapping. Here, I'm mapping the "name" field
            "name": {
                // Define the type -- I set it to "text" here so I can do full-text search
                "type": "text",
                // Define the analyzer this field will use. Analyzers will run when the field is populated (I.e Transform and Tokenize the text)
                "analyzer": "my_custom_analyzer"
                // DEFINE OTHER MAPPING PARAMETERS HERE
            }
        }
    }
}





Analyzers:
- Used during Indexing to break down sentences into terms
- This is run every time a new document is inserted

Consists of:
1. Character Filter: Receive the original text and transform it (E.g Remove characters, html tags, etc)
https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html
2. Tokenizer: Receive the text and break into individual tokens
https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenfilters.html
3. Token Filter: Perform transformation on the tokens (e.g Lowercase all tokens, remove stop words, etc.)

Analyzer can have zero or more character & token filters, but can only have ONE tokenizer
You can set the specific analyzer you want a field to use, when doing the Mapping

<Sample>

"settings" :{
    "analysis": {
        "analyzer": {
            // DEFINE ALL ANALYZERS HERE
        }
    }
}


E.g

"settings" :{
    "analysis": {
        "analyzer": {
            "my_custom_analyzer": {
                // Custom Tokenizer type
                "type": "custom",
                // Define the Character filter. Will strip all html from the received raw text
                "char_filter": ["html_strip"],
                // Use the whitespace tokenizer -- will tokenize words using whitespace as seperator
                "tokenizer": "whitespace",
                // Define the Token Filter. Will lowercase all tokens
                "filter": ["lowercase"]
            }
        }
    }
}




CUSTOM FILTERS
-- If you want to define your own filters (Can be for Character or Token) (I.e NGrams, etc.)
https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-tokenizers.html

"filter": {
    "my_custom_filter: {
        // PARAMS HERE
    }
}



E.g

"filter": {
    "my_autocomplete_filter": {
        "type": "edge_ngram",
        "min_gram": "1",
        "max_gram": "40"
    }
}